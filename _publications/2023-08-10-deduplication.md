---
title: "Scalable Incremental Checkpointing using GPU-Accelerated De-Duplication"
collection: publications
permalink: /publication/2023-08-10-deduplication
excerpt: 'Writing large amounts of data concurrently to stable storage is a typical I/O pattern of many HPC workflows. This pattern introduces high I/O overheads and results in increased storage space utilization especially for workflows that need to capture the evolution of data structures with high frequency as checkpoints. In this context, many applications, such as graph pattern matching, perform sparse updates to large data structures between checkpoints. For these applications, incremental checkpointing techniques that save only the differences from one checkpoint to another can dramatically reduce the checkpoint sizes, I/O bottlenecks, and storage space utilization. However, such techniques are not without challenges: it is non-trivial to transparently determine what data has changed since a previous checkpoint and assemble the differences in a compact fashion that does not result in excessive metadata. State-of-art data reduction techniques (e.g., compression and de-duplication) have significant limitations when applied to modern HPC applications that leverage GPUs: slow at detecting the differences, generate a large amount of metadata to keep track of the differences, and ignore crucial spatiotemporal checkpoint data redundancy. This paper addresses these challenges by proposing a Merkle tree-based incremental checkpointing method to exploit GPUs&apos; high memory bandwidth and massive parallelism. Experimental results at scale show a significant reduction of the I/O overhead and space utilization of checkpointing compared with state-of-the-art incremental checkpointing and compression techniques.'
date: 2023-08-10
venue: 'ICPP&apos;23: 52nd International Conference on Parallel Processing'
paperurl: 'https://hal.science/hal-04173764/document'
citation: 'Tan, N., Luettgau, J., Marquez, J., Terianishi, K., Morales, N., Bhowmick, S., ... &amp; Nicolae, B. (2023, August). Scalable Incremental Checkpointing using GPU-Accelerated De-Duplication. In ICPP&apos;23: 52nd International Conference on Parallel Processing.'
---

<a href='https://hal.science/hal-04173764/document'>Download paper here</a>

Writing large amounts of data concurrently to stable storage is a typical I/O pattern of many HPC workflows. This pattern introduces high I/O overheads and results in increased storage space utilization especially for workflows that need to capture the evolution of data structures with high frequency as checkpoints. In this context, many applications, such as graph pattern matching, perform sparse updates to large data structures between checkpoints. For these applications, incremental checkpointing techniques that save only the differences from one checkpoint to another can dramatically reduce the checkpoint sizes, I/O bottlenecks, and storage space utilization. However, such techniques are not without challenges: it is non-trivial to transparently determine what data has changed since a previous checkpoint and assemble the differences in a compact fashion that does not result in excessive metadata. State-of-art data reduction techniques (e.g., compression and de-duplication) have significant limitations when applied to modern HPC applications that leverage GPUs: slow at detecting the differences, generate a large amount of metadata to keep track of the differences, and ignore crucial spatiotemporal checkpoint data redundancy. This paper addresses these challenges by proposing a Merkle tree-based incremental checkpointing method to exploit GPUs&apos; high memory bandwidth and massive parallelism. Experimental results at scale show a significant reduction of the I/O overhead and space utilization of checkpointing compared with state-of-the-art incremental checkpointing and compression techniques.

Recommended citation: Tan, N., Luettgau, J., Marquez, J., Terianishi, K., Morales, N., Bhowmick, S., ... & Nicolae, B. (2023, August). Scalable Incremental Checkpointing using GPU-Accelerated De-Duplication. In ICPP'23: 52nd International Conference on Parallel Processing.